{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c77d3b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36e8f529",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data = pd.read_json('Appliances_5.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b338a003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>08 22, 2013</td>\n",
       "      <td>A34A1UP40713F8</td>\n",
       "      <td>B00009W3I4</td>\n",
       "      <td>{'Style:': ' Dryer Vent'}</td>\n",
       "      <td>James. Backus</td>\n",
       "      <td>I like this as a vent as well as something tha...</td>\n",
       "      <td>Great product</td>\n",
       "      <td>1377129600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>02 8, 2016</td>\n",
       "      <td>A1AHW6I678O6F2</td>\n",
       "      <td>B00009W3PA</td>\n",
       "      <td>{'Size:': ' 6-Foot'}</td>\n",
       "      <td>kevin.</td>\n",
       "      <td>good item</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1454889600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>08 5, 2015</td>\n",
       "      <td>A8R48NKTGCJDQ</td>\n",
       "      <td>B00009W3PA</td>\n",
       "      <td>{'Size:': ' 6-Foot'}</td>\n",
       "      <td>CDBrannom</td>\n",
       "      <td>Fit my new LG dryer perfectly.</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1438732800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>04 24, 2015</td>\n",
       "      <td>AR3OHHHW01A8E</td>\n",
       "      <td>B00009W3PA</td>\n",
       "      <td>{'Size:': ' 6-Foot'}</td>\n",
       "      <td>Calvin E Reames</td>\n",
       "      <td>Good value for electric dryers</td>\n",
       "      <td>Perfect size</td>\n",
       "      <td>1429833600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>03 21, 2015</td>\n",
       "      <td>A2CIEGHZ7L1WWR</td>\n",
       "      <td>B00009W3PA</td>\n",
       "      <td>{'Size:': ' 6-Foot'}</td>\n",
       "      <td>albert j. kong</td>\n",
       "      <td>Price and delivery was excellent.</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1426896000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified   reviewTime      reviewerID        asin  \\\n",
       "0        5      True  08 22, 2013  A34A1UP40713F8  B00009W3I4   \n",
       "1        5      True   02 8, 2016  A1AHW6I678O6F2  B00009W3PA   \n",
       "2        5      True   08 5, 2015   A8R48NKTGCJDQ  B00009W3PA   \n",
       "3        5      True  04 24, 2015   AR3OHHHW01A8E  B00009W3PA   \n",
       "4        5      True  03 21, 2015  A2CIEGHZ7L1WWR  B00009W3PA   \n",
       "\n",
       "                       style     reviewerName  \\\n",
       "0  {'Style:': ' Dryer Vent'}    James. Backus   \n",
       "1       {'Size:': ' 6-Foot'}           kevin.   \n",
       "2       {'Size:': ' 6-Foot'}        CDBrannom   \n",
       "3       {'Size:': ' 6-Foot'}  Calvin E Reames   \n",
       "4       {'Size:': ' 6-Foot'}   albert j. kong   \n",
       "\n",
       "                                          reviewText        summary  \\\n",
       "0  I like this as a vent as well as something tha...  Great product   \n",
       "1                                          good item     Five Stars   \n",
       "2                     Fit my new LG dryer perfectly.     Five Stars   \n",
       "3                     Good value for electric dryers   Perfect size   \n",
       "4                  Price and delivery was excellent.     Five Stars   \n",
       "\n",
       "   unixReviewTime vote image  \n",
       "0      1377129600  NaN   NaN  \n",
       "1      1454889600  NaN   NaN  \n",
       "2      1438732800  NaN   NaN  \n",
       "3      1429833600  NaN   NaN  \n",
       "4      1426896000  NaN   NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b52fed1",
   "metadata": {},
   "source": [
    "### Filter our Column we want to analyse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e6a554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Filter_review = review_data[['overall','reviewText','summary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51ed59cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>I like this as a vent as well as something tha...</td>\n",
       "      <td>Great product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>good item</td>\n",
       "      <td>Five Stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Fit my new LG dryer perfectly.</td>\n",
       "      <td>Five Stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Good value for electric dryers</td>\n",
       "      <td>Perfect size</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Price and delivery was excellent.</td>\n",
       "      <td>Five Stars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall                                         reviewText        summary\n",
       "0        5  I like this as a vent as well as something tha...  Great product\n",
       "1        5                                          good item     Five Stars\n",
       "2        5                     Fit my new LG dryer perfectly.     Five Stars\n",
       "3        5                     Good value for electric dryers   Perfect size\n",
       "4        5                  Price and delivery was excellent.     Five Stars"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Filter_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff9dffa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall\n",
      "5    0.707949\n",
      "3    0.184892\n",
      "4    0.097497\n",
      "2    0.005709\n",
      "1    0.003953\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(Filter_review.overall.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae86b659",
   "metadata": {},
   "source": [
    "overall we have a high rating of 5 & 4 which shows how our customer like the product but we have also bad reviews which can help us to improve the product for everyone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9632b6",
   "metadata": {},
   "source": [
    "## Corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b7ed6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of our corpus is: 2277 \n",
      "\n",
      "The first Review in our corpus is:\n",
      " I like this as a vent as well as something that will keep house warmer in winter.  I sanded it and then painted it the same color as the house.  Looks great.\n"
     ]
    }
   ],
   "source": [
    "corpus =  Filter_review.reviewText.tolist()\n",
    "\n",
    "print(\"The size of our corpus is:\", len(corpus), \"\\n\")\n",
    "print(\"The first Review in our corpus is:\\n\", corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbb3a62",
   "metadata": {},
   "source": [
    "##  Tokenization\n",
    "\n",
    "tokenization is a process of dividing documents(corpus) into individual meaningful tokens that make a document (corpus).\n",
    "nltk is a wonderful package that provides tokenization tools that perform very well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4777ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/marshal/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f67b9956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Review:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'We would give less than 1 star if possible DONT BUY THIS PRODUCT.  The ice machine stopped working four hours after we used it the first time.  We notified New Air and they stated they would not honor their one year warranty because \"an authorized dealer didn\\'t sell\".  We bought this product on Amazon and never even thought we would have to cross check our purchase with the manufacturer.  NewAir does not stand by their products and they will use any method to get out of honoring their warranty.  I have a $200 piece of junk now, I will NEVER buy another NewAir product again.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "print ('Original Review:')\n",
    "Filter_review.reviewText[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57726767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence Tokenized:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['We would give less than 1 star if possible DONT BUY THIS PRODUCT.',\n",
       " 'The ice machine stopped working four hours after we used it the first time.',\n",
       " 'We notified New Air and they stated they would not honor their one year warranty because \"an authorized dealer didn\\'t sell\".',\n",
       " 'We bought this product on Amazon and never even thought we would have to cross check our purchase with the manufacturer.',\n",
       " 'NewAir does not stand by their products and they will use any method to get out of honoring their warranty.',\n",
       " 'I have a $200 piece of junk now, I will NEVER buy another NewAir product again.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('sentence Tokenized:')\n",
    "sent_tokenize(Filter_review.reviewText[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ac3071",
   "metadata": {},
   "source": [
    "Notice that the resulting output is a list of sentences. The sent_tokenize uses heuristic rules about the English language to separate sentences. In this case, look for periods and punctuation that separate complete sentences i.e. !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbc413e",
   "metadata": {},
   "source": [
    "### Punckt Sentence Tokenizer\n",
    "\n",
    "Another sentence tokenizer is the PunktSentenceTokenizer which performs similarly and may be more effective in some instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96921020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We would give less than 1 star if possible DONT BUY THIS PRODUCT.',\n",
       " 'The ice machine stopped working four hours after we used it the first time.',\n",
       " 'We notified New Air and they stated they would not honor their one year warranty because \"an authorized dealer didn\\'t sell\".',\n",
       " 'We bought this product on Amazon and never even thought we would have to cross check our purchase with the manufacturer.',\n",
       " 'NewAir does not stand by their products and they will use any method to get out of honoring their warranty.',\n",
       " 'I have a $200 piece of junk now, I will NEVER buy another NewAir product again.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "\n",
    "punkt_sent_tokenizer = PunktSentenceTokenizer()\n",
    "punkt_sent_tokenizer.tokenize( Filter_review.reviewText[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53694571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word Tokenizer: ['I', 'like', 'this', 'as', 'a', 'vent', 'as', 'well', 'as', 'something', 'that', 'will', 'keep', 'house', 'warmer', 'in', 'winter', '.', 'I', 'sanded', 'it', 'and', 'then', 'painted', 'it', 'the', 'same', 'color', 'as', 'the', 'house', '.', 'Looks', 'great', '.']\n"
     ]
    }
   ],
   "source": [
    " from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "    \n",
    "print(\"word Tokenizer:\", word_tokenize(corpus[0]))\n",
    "#print(\"word punct Tokenizer:\", wordpunct_tokenize(corpus[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d03fd9",
   "metadata": {},
   "source": [
    "The output above displays the words generated by both word tokenizers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689810c4",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "\n",
    "Stemming is the process of reducing texts to their root words. This feature is powerful as it allows us to reduce the number of tokens in a document or corpus significantly while retaining the context as much as possible. In the example below, we implement two stemmers on the set of variants with the same root.\n",
    "\n",
    "Let's see the examples of stemmers in nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fb3d71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "\n",
    "porter_stem = PorterStemmer()\n",
    "snowb_stem = SnowballStemmer('english') # Need to initialize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9738a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('love', 'love', 'love')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter_stem.stem(\"loved\"), porter_stem.stem(\"lovely\"), porter_stem.stem(\"loveness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a498384b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('amaz', 'amaz', 'amaz', 'amaz')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowb_stem.stem('amazing'), snowb_stem.stem('amazed'), snowb_stem.stem('amazes'), snowb_stem.stem('amazingly')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d989a5",
   "metadata": {},
   "source": [
    "## Lemmatization\n",
    "Lemmatization also performs stemming however, it uses vocabulary and morphology to return the base of the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aff7e16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/marshal/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "faab4326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('wolf', 'say', 'be')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "lemmatizer.lemmatize(\"wolves\"), lemmatizer.lemmatize(\"saying\", pos='v'), lemmatizer.lemmatize(\"is\", pos='v')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaffb0f",
   "metadata": {},
   "source": [
    "## Stop Words\n",
    "Stopwords are words that are part of the grammatical structure of the language but do not carry much semantic meaning to the text. These are often frequent words like 'is' and 'the' that whether they are in or out of the text, the meaning does not change. In NLP, we often deal with stopwords by removing them or selecting what to retain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "605d5aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/marshal/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f60088b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Stop words: the restaurant at the city served amazing food \n",
      "\n",
      "Without Stop words: restaurant city served amazing food\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "sentence = \"the restaurant at the city served amazing food\"\n",
    "print(\"With Stop words:\", sentence, \"\\n\" )\n",
    "\n",
    "without_stopwords = [word for word in word_tokenize(sentence) if word not in stopwords.words('english')]\n",
    "print('Without Stop words:', ' '.join(without_stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e32d0f",
   "metadata": {},
   "source": [
    "## Combining All Preprocessing Steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ac0ef2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c0b19d",
   "metadata": {},
   "source": [
    "### Text Cleaning:\n",
    "\n",
    "        - Remove Punctuation\n",
    "        - Remove Numbers\n",
    "        - Tokenize Text\n",
    "        - Stem Text\n",
    "        - Remove Stopwords\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5cf0fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "def cleaningText(text):\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text) # Remove non-alphabetic character\n",
    "    text = re.sub(\"[0-9]+\", \"\", text) # Remove Numbers\n",
    "    text = [ porter_stemmer.stem(word.lower()) for word in word_tokenize(text) if word not in stopwords.words('english') ]\n",
    "    return \" \".join(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "987c0e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the restaurant realli amaz servic great food'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaningText(\"The restaurantant has really amazing service and great food\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a84a5adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'we would give less star possibl dont buy thi product the ice machin stop work four hour use first time we notifi new air state would honor one year warranti author dealer sell we bought product amazon never even thought would cross check purchas manufactur newair stand product use method get honor warranti i piec junk i never buy anoth newair product'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaningText(\"We would give less than 1 star if possible DONT BUY THIS PRODUCT.  The ice machine stopped working four hours after we used it the first time.  We notified New Air and they stated they would not honor their one year warranty because an authorized dealer didn't sell.  We bought this product on Amazon and never even thought we would have to cross check our purchase with the manufacturer.  NewAir does not stand by their products and they will use any method to get out of honoring their warranty.  I have a $200 piece of junk now, I will NEVER buy another NewAir product again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063c9abf",
   "metadata": {},
   "source": [
    "## running the Preprocesing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdd41c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39888/2080681682.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Filter_review['clean_review'] = Filter_review.reviewText.apply( lambda x: cleaningText( str(x)))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>clean_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I like this as a vent as well as something tha...</td>\n",
       "      <td>i like vent well someth keep hous warmer winte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good item</td>\n",
       "      <td>good item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fit my new LG dryer perfectly.</td>\n",
       "      <td>fit new lg dryer perfectli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good value for electric dryers</td>\n",
       "      <td>good valu electr dryer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Price and delivery was excellent.</td>\n",
       "      <td>price deliveri excel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  \\\n",
       "0  I like this as a vent as well as something tha...   \n",
       "1                                          good item   \n",
       "2                     Fit my new LG dryer perfectly.   \n",
       "3                     Good value for electric dryers   \n",
       "4                  Price and delivery was excellent.   \n",
       "\n",
       "                                        clean_review  \n",
       "0  i like vent well someth keep hous warmer winte...  \n",
       "1                                          good item  \n",
       "2                         fit new lg dryer perfectli  \n",
       "3                             good valu electr dryer  \n",
       "4                               price deliveri excel  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Filter_review['clean_review'] = Filter_review.reviewText.apply( lambda x: cleaningText( str(x)))\n",
    "Filter_review[['reviewText','clean_review']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa7d879",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
